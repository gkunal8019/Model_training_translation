{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRSNbEGN0Cuh",
        "outputId": "1cbe6fa6-a9de-4d57-edf6-055750c1fc51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Collecting ctranslate2\n",
            "  Downloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.6.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading ctranslate2-4.6.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (38.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.6.0-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, ctranslate2, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 ctranslate2-4.6.3 portalocker-3.2.0 sacrebleu-2.6.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (5.29.5)\n"
          ]
        }
      ],
      "source": [
        "# COMPLETE TRANSLITERATION PROJECT COLAB CODE\n",
        "# Indic-to-English (Roman) for Hindi, Bengali, Tamil using Aksharantar + mT5 + CTranslate2 + Gradio\n",
        "# Run this step-by-step in Google Colab (GPU recommended)\n",
        "\n",
        "# ===== STEP 1: INSTALL DEPENDENCIES =====\n",
        "!pip install datasets transformers torch accelerate ctranslate2 gradio huggingface_hub sacrebleu\n",
        "!pip install sentencepiece protobuf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ULTRA-FAST STEP 2: LOAD & PREPROCESS DATASET =====\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "\n",
        "# Load with streaming and take only first 3000 total examples (1 minute max)\n",
        "print(\"Loading tiny subset for fast execution...\")\n",
        "\n",
        "stream_ds = load_dataset(\n",
        "    \"ai4bharat/Aksharantar\",\n",
        "    \"default\",\n",
        "    split=\"train\",\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "# Collect examples without filtering - just grab first N\n",
        "examples_list = []\n",
        "target_langs = {\"hin\", \"ben\", \"tam\"}  # We want these but won't strictly filter for speed\n",
        "\n",
        "for i, example in enumerate(stream_ds):\n",
        "    if i >= 3000:  # Stop after 3000 examples total\n",
        "        break\n",
        "\n",
        "    # Check if the example has the required keys\n",
        "    # Print first example to debug\n",
        "    if i == 0:\n",
        "        print(f\"First example keys: {example.keys()}\")\n",
        "        print(f\"Sample values: {list(example.items())[:3]}\")\n",
        "\n",
        "    # Try different possible key names\n",
        "    if \"target\" in example and \"source\" in example:\n",
        "        # Original format: target=Indic, source=English\n",
        "        examples_list.append({\n",
        "            \"input\": example[\"target\"],\n",
        "            \"output\": example[\"source\"]\n",
        "        })\n",
        "    elif \"native word\" in example and \"english word\" in example:\n",
        "        examples_list.append({\n",
        "            \"input\": example[\"native word\"],\n",
        "            \"output\": example[\"english word\"]\n",
        "        })\n",
        "\n",
        "# Create dataset\n",
        "combined_ds = Dataset.from_list(examples_list)\n",
        "\n",
        "# Split 80/20\n",
        "split_result = combined_ds.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "combined = DatasetDict({\n",
        "    \"train\": split_result[\"train\"],\n",
        "    \"test\": split_result[\"test\"]\n",
        "})\n",
        "\n",
        "print(f\"\\nTraining samples: {len(combined['train'])}, Test samples: {len(combined['test'])}\")\n",
        "print(\"Ready for Step 3 (training)!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ace15c50ea5a41bab8d949154b0b5734",
            "1c5404549c74437785be249a4ee5a618",
            "d68f5e7bc30a41d3bfa669e7776a1c3b",
            "5db1dc8bb38a4c3d9fe772c4fc182000",
            "d83c0dfbb3864da09eb68bbe4223a35d",
            "42958a62308f44ee81173ca0108b7f09",
            "157de5b34e7f4ab5a8e2edb2afea0b82",
            "82b2fd2c9de74aa7b8af78473d1f834b",
            "e5d1a62d894648868904fca2d3bc9baf",
            "8eb3a15daa7d47cfa719898927a13bdc",
            "70221b3b78324efd932951a6fd8e4899"
          ]
        },
        "id": "5qULuruvVJDe",
        "outputId": "a58e8ec2-01de-47ca-e6fe-1b3463b0004a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tiny subset for fast execution...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ace15c50ea5a41bab8d949154b0b5734"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First example keys: dict_keys(['unique_identifier', 'native word', 'english word', 'source'])\n",
            "Sample values: [('unique_identifier', 'asm1'), ('native word', 'লক্ষীনগৰস্থিত'), ('english word', 'lakhyeenogorsthito')]\n",
            "\n",
            "Training samples: 2400, Test samples: 600\n",
            "Ready for Step 3 (training)!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WdYyy4ifz1qQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "9fa3e345601f43d780a4d9b5e09b2c32",
            "ccf02a487c9244e78116acde4649fb2c",
            "817d71756ca347a7a935f405121eee42",
            "09fb4703051a4cfdb2d0222808c5ec23",
            "ec53a8271b2f48dbaeafc2653f983645",
            "7a69bdf0003543aa8ba79b1033e71f4a",
            "9082e23ad9bb4f43a371353bac65fd51",
            "b07a82a450ce404399a8547e7b344312",
            "1f046e54ff2b41e9bfc5cc77108aea1a",
            "e8c0179fe8e249c2b7036e12734b0f81",
            "59516752a829445ab8e11ea17a20a0f9",
            "d06243a3989f48c0bf6c8ddd7f73b6aa",
            "57b2be17eb9746048ba33265e46f9d9b",
            "55252968413346389558c45509b84008",
            "f91918d7d61a47b99f5ab673946255c6",
            "c1abb20b73274c40a2ebe552fd289643",
            "0fe1547436fa4aed9af3198403458710",
            "15912d0956b848ab9c8dafa454aa1af9",
            "6efbe00838a54c919639b7edacb11b43",
            "cf71c12913da406e8b2dd8425a5deb90",
            "535cb38709524dea99596f663325738a",
            "a26ed0a8ae684dc68d61b6c7ce39caaa"
          ]
        },
        "outputId": "7b2f69a1-03d8-4811-ef06-b90381312cd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fa3e345601f43d780a4d9b5e09b2c32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06243a3989f48c0bf6c8ddd7f73b6aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cpu\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-627929051.py:46: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 16:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>24.732600</td>\n",
              "      <td>21.611090</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Model saved to ./translit-model\n"
          ]
        }
      ],
      "source": [
        "# ===== COMPATIBLE STEP 3: TRAIN mT5 MODEL =====\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "import torch\n",
        "\n",
        "model_name = \"google/mt5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def preprocess(examples):\n",
        "    inputs = [f\"transliterate: {inp}\" for inp in examples[\"input\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=False)\n",
        "    labels = tokenizer(examples[\"output\"], max_length=128, truncation=True, padding=False)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = combined.map(preprocess, batched=True, remove_columns=combined[\"train\"].column_names)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "use_fp16 = torch.cuda.is_available()\n",
        "\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "# Use eval_strategy instead of evaluation_strategy (newer transformers versions)\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./translit-model\",\n",
        "    eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=use_fp16,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model(\"./translit-model\")\n",
        "tokenizer.save_pretrained(\"./translit-model\")\n",
        "print(\"Training complete! Model saved to ./translit-model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r95TvJVIz9Xi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a1b9ff-5112-422e-a768-61bb4f0838b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions with improved decoding...\n",
            "\n",
            "CHRF Score: 5.39%\n",
            "Evaluated on 600 test samples\n",
            "\n",
            "=== Sample Predictions ===\n",
            "Input:      সন্ত্রাসবাদীসকলক\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  xantrasbadixokolok\n",
            "--------------------------------------------------\n",
            "Input:      আগে\n",
            "Predicted:  <extra_id_0>।\n",
            "Reference:  aage\n",
            "--------------------------------------------------\n",
            "Input:      বনোৱালৈকে\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  bonuwaloike\n",
            "--------------------------------------------------\n",
            "Input:      দুখ\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  dukh\n",
            "--------------------------------------------------\n",
            "Input:      জীৱনক\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  jeewonok\n",
            "--------------------------------------------------\n",
            "Input:      অফাৰসমূহ\n",
            "Predicted:  <extra_id_0>সমূহ\n",
            "Reference:  offerxomuh\n",
            "--------------------------------------------------\n",
            "Input:      কলম\n",
            "Predicted:  <extra_id_0>)\n",
            "Reference:  kolom\n",
            "--------------------------------------------------\n",
            "Input:      বন্দীকো\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  bondiku\n",
            "--------------------------------------------------\n",
            "Input:      তবুৰ\n",
            "Predicted:  <extra_id_0>ৰ\n",
            "Reference:  tobur\n",
            "--------------------------------------------------\n",
            "Input:      চৌহদ\n",
            "Predicted:  <extra_id_0>.\n",
            "Reference:  chouhod\n",
            "--------------------------------------------------\n",
            "\n",
            "Sentinel/empty outputs: 600/600 (100.0%)\n"
          ]
        }
      ],
      "source": [
        "# ===== STEP 4: EVALUATE (IMPROVED GENERATION) =====\n",
        "from sacrebleu.metrics import CHRF\n",
        "import torch\n",
        "\n",
        "def generate_predictions(model, tokenizer, test_dataset, max_new_tokens=64):\n",
        "    \"\"\"Generate predictions with improved generation parameters\"\"\"\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = 8\n",
        "    for i in range(0, len(test_dataset), batch_size):\n",
        "        batch = test_dataset[i:min(i+batch_size, len(test_dataset))]\n",
        "\n",
        "        # Prepare inputs\n",
        "        input_texts = [f\"transliterate: {inp}\" for inp in batch[\"input\"]]\n",
        "        inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "\n",
        "        # IMPROVED: Use beam search and force longer outputs\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=64,  #\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=2,\n",
        "                temperature=0.8,\n",
        "                do_sample=False,\n",
        "                min_length=3,\n",
        "                forced_bos_token_id=None,\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        pred_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        ref_texts = batch[\"output\"]\n",
        "\n",
        "        predictions.extend(pred_texts)\n",
        "        references.extend(ref_texts)\n",
        "\n",
        "    return predictions, references\n",
        "\n",
        "print(\"Generating predictions with improved decoding...\")\n",
        "\n",
        "# Use the correct test dataset\n",
        "if 'tiny_test' in locals():\n",
        "    test_data = tiny_test\n",
        "else:\n",
        "    test_data = combined[\"test\"]\n",
        "\n",
        "preds, refs = generate_predictions(model, tokenizer, test_data)\n",
        "\n",
        "# Calculate CHRF score\n",
        "chrf = CHRF()\n",
        "score = chrf.corpus_score(preds, [refs])\n",
        "print(f\"\\nCHRF Score: {score.score:.2f}%\")\n",
        "print(f\"Evaluated on {len(preds)} test samples\")\n",
        "\n",
        "# Show examples\n",
        "print(\"\\n=== Sample Predictions ===\")\n",
        "for i in range(min(10, len(preds))):  # Show 10 examples\n",
        "    print(f\"Input:      {test_data[i]['input']}\")\n",
        "    print(f\"Predicted:  {preds[i]}\")\n",
        "    print(f\"Reference:  {refs[i]}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Count how many are still sentinel tokens\n",
        "sentinel_count = sum(1 for p in preds if '<extra_id' in p or p.strip() == '')\n",
        "print(f\"\\nSentinel/empty outputs: {sentinel_count}/{len(preds)} ({sentinel_count/len(preds)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kxiZFoO7z6qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d8b152-7ca9-4db2-c0da-cc52ba78032f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-21 12:30:00.909475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768998600.935904   18191 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768998600.945366   18191 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768998600.981480   18191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768998600.981529   18191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768998600.981535   18191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768998600.981538   18191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "The tokenizer you are loading from './translit-model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Testing with input: नमस्ते\n",
            "Tokens: ['▁trans', 'liter', 'ate', ':', '▁', 'न', 'मस्', 'ते']...\n",
            "\n",
            "CT2 Output: <extra_id_0> <extra_id_46> <extra_id_31> <extra_id_51>\n",
            "CTranslate2 latency: 217.40ms\n",
            "Original latency: 202.03ms\n",
            "Speed gain: -7.6%\n",
            "\n",
            "Model size comparison:\n",
            "Original: 1164.8MB\n",
            "Optimized (CT2 int8): 293.2MB\n",
            "Size reduction: 74.8%\n"
          ]
        }
      ],
      "source": [
        "# ===== STEP 5: OPTIMIZE WITH CTRANSLATE2 (CORRECTED) =====\n",
        "!ct2-transformers-converter --model ./translit-model --output_dir ./translit-ct2 --quantization int8 --force\n",
        "\n",
        "import time\n",
        "import ctranslate2\n",
        "\n",
        "# Load CT2 model\n",
        "ct2_model = ctranslate2.Translator(\"./translit-ct2\")\n",
        "\n",
        "# Prepare test input - CT2 needs token strings, not IDs\n",
        "test_input = \"नमस्ते\"  # Hindi test\n",
        "input_text = f\"transliterate: {test_input}\"\n",
        "\n",
        "# Tokenize and convert to string tokens (what CT2 expects)\n",
        "tokens = tokenizer.tokenize(input_text)\n",
        "\n",
        "print(f\"Testing with input: {test_input}\")\n",
        "print(f\"Tokens: {tokens[:10]}...\")  # Show first 10 tokens\n",
        "\n",
        "# === CT2 Benchmark ===\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    results = ct2_model.translate_batch(\n",
        "        source=[tokens],  # List of token lists\n",
        "        max_decoding_length=64,\n",
        "        beam_size=2\n",
        "    )\n",
        "end = time.time()\n",
        "ct2_latency = (end - start) / 100 * 1000  # ms per inference\n",
        "\n",
        "# Show CT2 output\n",
        "ct2_output_tokens = results[0].hypotheses[0]\n",
        "ct2_output = tokenizer.convert_tokens_to_string(ct2_output_tokens)\n",
        "print(f\"\\nCT2 Output: {ct2_output}\")\n",
        "print(f\"CTranslate2 latency: {ct2_latency:.2f}ms\")\n",
        "\n",
        "# === Original Model Benchmark ===\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    with torch.no_grad():\n",
        "        model.generate(inputs[\"input_ids\"], max_new_tokens=64)\n",
        "end = time.time()\n",
        "orig_latency = (end - start) / 100 * 1000\n",
        "\n",
        "print(f\"Original latency: {orig_latency:.2f}ms\")\n",
        "print(f\"Speed gain: {((orig_latency - ct2_latency)/orig_latency)*100:.1f}%\")\n",
        "\n",
        "# === Model Size Comparison ===\n",
        "import os\n",
        "\n",
        "def get_dir_size(path):\n",
        "    total = 0\n",
        "    for entry in os.listdir(path):\n",
        "        full_path = os.path.join(path, entry)\n",
        "        if os.path.isfile(full_path):\n",
        "            total += os.path.getsize(full_path)\n",
        "    return total / (1024**2)  # Convert to MB\n",
        "\n",
        "orig_size = get_dir_size(\"./translit-model\")\n",
        "ct2_size = get_dir_size(\"./translit-ct2\")\n",
        "\n",
        "print(f\"\\nModel size comparison:\")\n",
        "print(f\"Original: {orig_size:.1f}MB\")\n",
        "print(f\"Optimized (CT2 int8): {ct2_size:.1f}MB\")\n",
        "print(f\"Size reduction: {(1-ct2_size/orig_size)*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "09Nj_EHJz4J7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "cfeb9a55-4c89-4b9e-9928-6e2731bf03cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://16402596597284f351.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://16402596597284f351.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://3b67c4054e5e93850f.gradio.live\n",
            "Killing tunnel 127.0.0.1:7863 <> https://16402596597284f351.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# ===== STEP 6: GRADIO DEMO (CORRECTED) =====\n",
        "import gradio as gr\n",
        "\n",
        "def transliterate(text, language):\n",
        "    if not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "    input_text = f\"transliterate: {text}\"\n",
        "\n",
        "    # Convert to token STRINGS (not IDs) for CT2\n",
        "    tokens = ct2_tokenizer.tokenize(input_text)\n",
        "\n",
        "    # Translate with CT2\n",
        "    results = ct2_model.translate_batch(\n",
        "        source=[tokens],  # List[List[str]]\n",
        "        max_decoding_length=64,\n",
        "        beam_size=2\n",
        "    )\n",
        "\n",
        "    # Decode output tokens back to text\n",
        "    output_tokens = results[0].hypotheses[0]\n",
        "    output = ct2_tokenizer.convert_tokens_to_string(output_tokens)\n",
        "\n",
        "    # Clean up the output\n",
        "    output = output.replace(\"transliterate:\", \"\").strip()\n",
        "\n",
        "    # If model outputs sentinel token (undertrained), use fallback message\n",
        "    if \"<extra_id\" in output or not output:\n",
        "        return \"[Model undertrained - outputs sentinel tokens]\"\n",
        "\n",
        "    return output\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=transliterate,\n",
        "    inputs=[\n",
        "        gr.Textbox(\n",
        "            label=\"Indic Input Text\",\n",
        "            placeholder=\"नमस्ते (Hindi), নমস্কার (Bengali), or வணக்கம் (Tamil)\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            choices=[\"hin\", \"ben\", \"tam\"],\n",
        "            label=\"Language (for reference)\",\n",
        "            value=\"hin\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"English Roman Output\"),\n",
        "    title=\"Indic → English Transliterator\",\n",
        "    description=\"Enter text in Hindi/Bengali/Tamil script → Get Romanized English\\n\\n⚠️ Note: Model trained on minimal dataset for demo purposes\",\n",
        "    examples=[\n",
        "        [\"नमस्ते\", \"hin\"],\n",
        "        [\"কলম\", \"ben\"],\n",
        "        [\"வணக்கம்\", \"tam\"]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Launch with public link\n",
        "print(\"Launching Gradio interface...\")\n",
        "iface.launch(share=True, debug=True)  # Set debug=False to reduce console spam\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ace15c50ea5a41bab8d949154b0b5734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c5404549c74437785be249a4ee5a618",
              "IPY_MODEL_d68f5e7bc30a41d3bfa669e7776a1c3b",
              "IPY_MODEL_5db1dc8bb38a4c3d9fe772c4fc182000"
            ],
            "layout": "IPY_MODEL_d83c0dfbb3864da09eb68bbe4223a35d"
          }
        },
        "1c5404549c74437785be249a4ee5a618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42958a62308f44ee81173ca0108b7f09",
            "placeholder": "​",
            "style": "IPY_MODEL_157de5b34e7f4ab5a8e2edb2afea0b82",
            "value": "Resolving data files: 100%"
          }
        },
        "d68f5e7bc30a41d3bfa669e7776a1c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b2fd2c9de74aa7b8af78473d1f834b",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5d1a62d894648868904fca2d3bc9baf",
            "value": 21
          }
        },
        "5db1dc8bb38a4c3d9fe772c4fc182000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eb3a15daa7d47cfa719898927a13bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_70221b3b78324efd932951a6fd8e4899",
            "value": " 21/21 [00:00&lt;00:00, 1404.61it/s]"
          }
        },
        "d83c0dfbb3864da09eb68bbe4223a35d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42958a62308f44ee81173ca0108b7f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "157de5b34e7f4ab5a8e2edb2afea0b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b2fd2c9de74aa7b8af78473d1f834b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d1a62d894648868904fca2d3bc9baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eb3a15daa7d47cfa719898927a13bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70221b3b78324efd932951a6fd8e4899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fa3e345601f43d780a4d9b5e09b2c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccf02a487c9244e78116acde4649fb2c",
              "IPY_MODEL_817d71756ca347a7a935f405121eee42",
              "IPY_MODEL_09fb4703051a4cfdb2d0222808c5ec23"
            ],
            "layout": "IPY_MODEL_ec53a8271b2f48dbaeafc2653f983645"
          }
        },
        "ccf02a487c9244e78116acde4649fb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a69bdf0003543aa8ba79b1033e71f4a",
            "placeholder": "​",
            "style": "IPY_MODEL_9082e23ad9bb4f43a371353bac65fd51",
            "value": "Map: 100%"
          }
        },
        "817d71756ca347a7a935f405121eee42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07a82a450ce404399a8547e7b344312",
            "max": 2400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f046e54ff2b41e9bfc5cc77108aea1a",
            "value": 2400
          }
        },
        "09fb4703051a4cfdb2d0222808c5ec23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8c0179fe8e249c2b7036e12734b0f81",
            "placeholder": "​",
            "style": "IPY_MODEL_59516752a829445ab8e11ea17a20a0f9",
            "value": " 2400/2400 [00:00&lt;00:00, 6159.49 examples/s]"
          }
        },
        "ec53a8271b2f48dbaeafc2653f983645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a69bdf0003543aa8ba79b1033e71f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9082e23ad9bb4f43a371353bac65fd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b07a82a450ce404399a8547e7b344312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f046e54ff2b41e9bfc5cc77108aea1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8c0179fe8e249c2b7036e12734b0f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59516752a829445ab8e11ea17a20a0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06243a3989f48c0bf6c8ddd7f73b6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57b2be17eb9746048ba33265e46f9d9b",
              "IPY_MODEL_55252968413346389558c45509b84008",
              "IPY_MODEL_f91918d7d61a47b99f5ab673946255c6"
            ],
            "layout": "IPY_MODEL_c1abb20b73274c40a2ebe552fd289643"
          }
        },
        "57b2be17eb9746048ba33265e46f9d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe1547436fa4aed9af3198403458710",
            "placeholder": "​",
            "style": "IPY_MODEL_15912d0956b848ab9c8dafa454aa1af9",
            "value": "Map: 100%"
          }
        },
        "55252968413346389558c45509b84008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efbe00838a54c919639b7edacb11b43",
            "max": 600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf71c12913da406e8b2dd8425a5deb90",
            "value": 600
          }
        },
        "f91918d7d61a47b99f5ab673946255c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535cb38709524dea99596f663325738a",
            "placeholder": "​",
            "style": "IPY_MODEL_a26ed0a8ae684dc68d61b6c7ce39caaa",
            "value": " 600/600 [00:00&lt;00:00, 5450.92 examples/s]"
          }
        },
        "c1abb20b73274c40a2ebe552fd289643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe1547436fa4aed9af3198403458710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15912d0956b848ab9c8dafa454aa1af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6efbe00838a54c919639b7edacb11b43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf71c12913da406e8b2dd8425a5deb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "535cb38709524dea99596f663325738a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26ed0a8ae684dc68d61b6c7ce39caaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}